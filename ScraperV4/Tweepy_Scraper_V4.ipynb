{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554d9ee5",
   "metadata": {},
   "source": [
    "# Scraper for Twitter Using Tweepy\n",
    "Package Github: https://github.com/tweepy/tweepy\n",
    "\n",
    "Package Documentation: https://tweepy.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8aff69",
   "metadata": {},
   "source": [
    "## Notebook Author: Martin Beck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e38a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install Tweepy if you don't already have the package\n",
    "# !pip install tweepy\n",
    "\n",
    "# Imports\n",
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f69264",
   "metadata": {},
   "source": [
    "## Credentials and Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d396c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "bearer_token = \"XXXXXXX\"\n",
    "\n",
    "client = tweepy.Client(bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77359a30",
   "metadata": {},
   "source": [
    "## Query by Username\n",
    "Function is focused on using Username to Search then providing a CSV file of that scrape using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1dc585a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def username_search_to_csv(username, count):\n",
    "    try:\n",
    "        # grabbing user id from username \n",
    "        user_id = client.get_user(username=username).data.id\n",
    "        \n",
    "        # Creation of query method using parameters\n",
    "        tweets = tweepy.Paginator(client.get_users_tweets, user_id, tweet_fields=[\"author_id\", \"created_at\", \"lang\", \"public_metrics\"], expansions=[\"author_id\"], max_results=100).flatten(limit = count)\n",
    "        \n",
    "        tweets_list = []\n",
    "        \n",
    "        # Pulling information from tweets generator\n",
    "        tweets_list = [[tweet.created_at, tweet.id, tweet.text, tweet.public_metrics[\"retweet_count\"], tweet.public_metrics[\"like_count\"]]for tweet in tweets]\n",
    "        \n",
    "        # Creation of dataframe from tweets list\n",
    "        tweets_df = pd.DataFrame(tweets_list, columns=[\"Created At\", \"Tweet Id\", \"Text\", \"Retweet Count\", \"Like Count\"])\n",
    "        \n",
    "        # Converting dataframe to CSV \n",
    "        tweets_df.to_csv(\"{}-tweets.csv\".format(username), sep=',', index = False)\n",
    "        \n",
    "        print(\"Completed Scrape!\"\")\n",
    "        \n",
    "    except BaseException as e:\n",
    "        print(\"failed on_status,\"\",str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1abdf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "username = \"BillGates\"\n",
    "count = 10\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "username_search_to_csv(username, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee4399",
   "metadata": {},
   "source": [
    "## Scrape by Keyword Search\n",
    "Function is focused on using Keyword Search then providing a CSV file of that scrape using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3198ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search_to_csv(keyword_search, count):\n",
    "    try:\n",
    "        # Creation of query method using parameters\n",
    "        tweets = tweepy.Paginator(client.search_recent_tweets, keyword_search, tweet_fields=[\"author_id\", \"created_at\", \"lang\", \"public_metrics\"], user_fields=[\"username\"]).flatten(limit = count)\n",
    "        \n",
    "        tweets_list = []\n",
    "        \n",
    "        # Pulling information from tweets generator\n",
    "        tweets_list = [[tweet.created_at, tweet.id, tweet.text, tweet.public_metrics[\"retweet_count\"], tweet.public_metrics[\"like_count\"]]for tweet in tweets]\n",
    "        \n",
    "        # Creation of dataframe from tweets list\n",
    "        tweets_df = pd.DataFrame(tweets_list, columns=[\"Created At\", \"Tweet Id\", \"Text\", \"Retweet Count\", \"Like Count\"])\n",
    "        \n",
    "        # Converting dataframe to CSV \n",
    "        tweets_df.to_csv(\"{}-tweets.csv\".format(keyword_search), sep=',', index = False)\n",
    "        \n",
    "        print(\"Completed Scrape!\"\")\n",
    "        \n",
    "    except BaseException as e:\n",
    "        print(\"failed on_status,\"\",str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adcbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "keyword_search = \"Dogs\"\n",
    "count = 10\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "keyword_search_to_csv(keyword_search, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
